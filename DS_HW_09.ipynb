{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNR7F6P38nuvBuQfGoMHSCd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P-NGCj4Tbdvl"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Flatten\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result 89.84"
      ],
      "metadata": {
        "id": "vlveRMryI_N-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresh = 0.898\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    if logs[\"val_accuracy\"] > thresh:\n",
        "        print(f\"\\nReached {thresh}% validation accuracy. Stopping training!\")\n",
        "        model.stop_training = True\n",
        "\n",
        "lambda_cb = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "lr_schedule_exp = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=False)\n",
        "\n",
        "def create_model():\n",
        "  model = Sequential([\n",
        "      Flatten(),\n",
        "      Dense(1024, activation='elu'),\n",
        "      Dense(512, activation='elu'),\n",
        "      Dense(256, activation='elu'),\n",
        "      Dense(128, activation='elu'),\n",
        "      Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=lr_schedule_exp),\n",
        "    loss=losses.sparse_categorical_crossentropy,\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  return model\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "model = create_model()\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=17,\n",
        "          batch_size=32,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[lambda_cb]\n",
        "      )\n",
        "results1 = model.evaluate(x_test, y_test)\n",
        "results2 = model.evaluate(x_train, y_train)\n",
        "\n",
        "print(f'Train results: {results2}')\n",
        "print(f'Test results: {results1}')\n",
        "print(f'Difference accuracy: {results2[1] - results1[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhiDG-hcb_fq",
        "outputId": "a1321757-f865-4545-c949-81eb754df5fc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.5169 - accuracy: 0.8135 - val_loss: 0.4418 - val_accuracy: 0.8386\n",
            "Epoch 2/17\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.3956 - accuracy: 0.8549 - val_loss: 0.4017 - val_accuracy: 0.8532\n",
            "Epoch 3/17\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.3554 - accuracy: 0.8689 - val_loss: 0.3980 - val_accuracy: 0.8581\n",
            "Epoch 4/17\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.3248 - accuracy: 0.8788 - val_loss: 0.3744 - val_accuracy: 0.8617\n",
            "Epoch 5/17\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.2995 - accuracy: 0.8873 - val_loss: 0.3762 - val_accuracy: 0.8571\n",
            "Epoch 6/17\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.2792 - accuracy: 0.8956 - val_loss: 0.3718 - val_accuracy: 0.8658\n",
            "Epoch 7/17\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.2616 - accuracy: 0.9013 - val_loss: 0.3333 - val_accuracy: 0.8826\n",
            "Epoch 8/17\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.2493 - accuracy: 0.9055 - val_loss: 0.3298 - val_accuracy: 0.8806\n",
            "Epoch 9/17\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2281 - accuracy: 0.9135 - val_loss: 0.3317 - val_accuracy: 0.8886\n",
            "Epoch 10/17\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2152 - accuracy: 0.9176 - val_loss: 0.3382 - val_accuracy: 0.8867\n",
            "Epoch 11/17\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.2017 - accuracy: 0.9219 - val_loss: 0.3356 - val_accuracy: 0.8868\n",
            "Epoch 12/17\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1872 - accuracy: 0.9274 - val_loss: 0.3318 - val_accuracy: 0.8939\n",
            "Epoch 13/17\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1744 - accuracy: 0.9322 - val_loss: 0.3317 - val_accuracy: 0.8932\n",
            "Epoch 14/17\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.1619 - accuracy: 0.9361\n",
            "Reached 0.898% validation accuracy. Stopping training!\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1618 - accuracy: 0.9361 - val_loss: 0.3299 - val_accuracy: 0.8984\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3299 - accuracy: 0.8984\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1429 - accuracy: 0.9452\n",
            "Train results: [0.14288535714149475, 0.9451666474342346]\n",
            "Test results: [0.3299103379249573, 0.8984000086784363]\n",
            "Difference accuracy: 0.04676663875579834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result 89.98"
      ],
      "metadata": {
        "id": "ryrhLjLrI5-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresh = 0.902\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    if logs[\"val_accuracy\"] > thresh:\n",
        "        print(f\"\\nReached {thresh}% validation accuracy. Stopping training!\")\n",
        "        model.stop_training = True\n",
        "\n",
        "lambda_cb = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "\n",
        "lr_schedule_poly = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=1000,\n",
        "    end_learning_rate=0.0001,\n",
        "    power=1.0,\n",
        "    cycle=False)\n",
        "\n",
        "def create_model():\n",
        "  model = Sequential([\n",
        "      Flatten(),\n",
        "      Dense(1024, activation='relu'),\n",
        "      Dense(512, activation='relu'),\n",
        "      Dense(256, activation='relu'),\n",
        "      Dense(128, activation='relu'),\n",
        "      Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=lr_schedule_poly),\n",
        "    loss=losses.sparse_categorical_crossentropy,\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  return model\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "model = create_model()\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=17,\n",
        "          batch_size=256,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[lambda_cb]\n",
        "      )\n",
        "results1 = model.evaluate(x_test, y_test)\n",
        "results2 = model.evaluate(x_train, y_train)\n",
        "\n",
        "print(f'Train results: {results2}')\n",
        "print(f'Test results: {results1}')\n",
        "print(f'Difference accuracy: {results2[1] - results1[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxrUO-RyHUJg",
        "outputId": "3e4455ce-d08d-451e-aaa2-5ec91ca12649"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "235/235 [==============================] - 2s 5ms/step - loss: 0.5142 - accuracy: 0.8178 - val_loss: 0.4456 - val_accuracy: 0.8445\n",
            "Epoch 2/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3532 - accuracy: 0.8704 - val_loss: 0.3848 - val_accuracy: 0.8619\n",
            "Epoch 3/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3004 - accuracy: 0.8894 - val_loss: 0.3353 - val_accuracy: 0.8782\n",
            "Epoch 4/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2647 - accuracy: 0.9018 - val_loss: 0.3230 - val_accuracy: 0.8848\n",
            "Epoch 5/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2393 - accuracy: 0.9109 - val_loss: 0.3146 - val_accuracy: 0.8874\n",
            "Epoch 6/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2311 - accuracy: 0.9144 - val_loss: 0.3190 - val_accuracy: 0.8871\n",
            "Epoch 7/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2236 - accuracy: 0.9171 - val_loss: 0.3113 - val_accuracy: 0.8885\n",
            "Epoch 8/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2167 - accuracy: 0.9190 - val_loss: 0.3112 - val_accuracy: 0.8893\n",
            "Epoch 9/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9230 - val_loss: 0.3015 - val_accuracy: 0.8929\n",
            "Epoch 10/17\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2030 - accuracy: 0.9255 - val_loss: 0.3048 - val_accuracy: 0.8920\n",
            "Epoch 11/17\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1952 - accuracy: 0.9279 - val_loss: 0.3080 - val_accuracy: 0.8946\n",
            "Epoch 12/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1900 - accuracy: 0.9292 - val_loss: 0.3198 - val_accuracy: 0.8918\n",
            "Epoch 13/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1825 - accuracy: 0.9328 - val_loss: 0.3023 - val_accuracy: 0.8995\n",
            "Epoch 14/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9360 - val_loss: 0.3065 - val_accuracy: 0.8994\n",
            "Epoch 15/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1685 - accuracy: 0.9383 - val_loss: 0.3121 - val_accuracy: 0.8972\n",
            "Epoch 16/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1606 - accuracy: 0.9411 - val_loss: 0.3122 - val_accuracy: 0.8928\n",
            "Epoch 17/17\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1533 - accuracy: 0.9430 - val_loss: 0.3142 - val_accuracy: 0.8998\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3142 - accuracy: 0.8998\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1428 - accuracy: 0.9484\n",
            "Train results: [0.1428144872188568, 0.9484000205993652]\n",
            "Test results: [0.31416621804237366, 0.8998000025749207]\n",
            "Difference accuracy: 0.04860001802444458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('result 89.98')"
      ],
      "metadata": {
        "id": "aoYxyme_NuNs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result 89.78"
      ],
      "metadata": {
        "id": "pbpRLPXIN7Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresh = 0.902\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    if logs[\"val_accuracy\"] > thresh:\n",
        "        print(f\"\\nReached {thresh}% validation accuracy. Stopping training!\")\n",
        "        model.stop_training = True\n",
        "\n",
        "lambda_cb = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "lr_schedule_exp = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=False)\n",
        "\n",
        "def create_model():\n",
        "  model = Sequential([\n",
        "      Flatten(),\n",
        "      Dense(1024, activation='elu'),\n",
        "      Dense(512, activation='elu'),\n",
        "      Dense(256, activation='elu'),\n",
        "      Dense(128, activation='elu'),\n",
        "      Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=lr_schedule_exp),\n",
        "    loss=losses.sparse_categorical_crossentropy,\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  return model\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "model = create_model()\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=15,\n",
        "          batch_size=32,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[lambda_cb]\n",
        "      )\n",
        "results1 = model.evaluate(x_test, y_test)\n",
        "results2 = model.evaluate(x_train, y_train)\n",
        "\n",
        "print(f'Train results: {results2}')\n",
        "print(f'Test results: {results1}')\n",
        "print(f'Difference accuracy: {results2[1] - results1[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJmyL0BKHX_J",
        "outputId": "16a87470-84a8-4799-a788-df4dc34e1878"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5187 - accuracy: 0.8126 - val_loss: 0.4274 - val_accuracy: 0.8480\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3977 - accuracy: 0.8540 - val_loss: 0.3938 - val_accuracy: 0.8578\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3544 - accuracy: 0.8677 - val_loss: 0.3755 - val_accuracy: 0.8629\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3275 - accuracy: 0.8791 - val_loss: 0.3683 - val_accuracy: 0.8685\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3043 - accuracy: 0.8865 - val_loss: 0.3383 - val_accuracy: 0.8782\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2793 - accuracy: 0.8953 - val_loss: 0.3616 - val_accuracy: 0.8721\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2604 - accuracy: 0.9011 - val_loss: 0.3399 - val_accuracy: 0.8819\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2454 - accuracy: 0.9075 - val_loss: 0.3208 - val_accuracy: 0.8864\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2302 - accuracy: 0.9119 - val_loss: 0.3291 - val_accuracy: 0.8851\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2159 - accuracy: 0.9173 - val_loss: 0.3491 - val_accuracy: 0.8874\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2023 - accuracy: 0.9219 - val_loss: 0.3289 - val_accuracy: 0.8977\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1876 - accuracy: 0.9272 - val_loss: 0.3365 - val_accuracy: 0.8925\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1754 - accuracy: 0.9334 - val_loss: 0.3311 - val_accuracy: 0.8930\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1601 - accuracy: 0.9387 - val_loss: 0.3403 - val_accuracy: 0.8997\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1490 - accuracy: 0.9418 - val_loss: 0.3770 - val_accuracy: 0.8978\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3770 - accuracy: 0.8978\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1370 - accuracy: 0.9467\n",
            "Train results: [0.13700658082962036, 0.9466500282287598]\n",
            "Test results: [0.37695011496543884, 0.8978000283241272]\n",
            "Difference accuracy: 0.04884999990463257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"result_89.78\")"
      ],
      "metadata": {
        "id": "GXq5TBw4LvPN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Висновок"
      ],
      "metadata": {
        "id": "zuyR6nVCYzSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перебравши сотні варіантів побудови моделі для датасету fashion_mnist, можна виділити три моделі, які спрацювали найкраще:\n",
        "\n",
        "**1.** Adam, Dense(1024-512-256-128-10), activation = 'elu', learning rate (0.001) with ExponentialDecay, epochs = 15, batch_size = 32\n",
        "\n",
        "*Acc test - 89.78%*\n",
        "\n",
        "*Acc train - 94.66%*\n",
        "\n",
        "*Acc Train - Acc test = 4.88%*\n",
        "\n",
        "**2.** Adam, Dense(1024-512-256-128-10), activation = 'elu', learning rate (0.001) with ExponentialDecay, epochs = 17, batch_size = 32\n",
        "\n",
        "*Acc test - 89.84%*\n",
        "\n",
        "*Acc train - 94.51%*\n",
        "\n",
        "*Acc Train - Acc test = 4.68%*\n",
        "\n",
        "**3.** Adam, Dense(1024-512-256-128-10), activation = 'relu', learning rate (0.001) with PolynomialDecay, epochs = 17, batch_size = 256\n",
        "\n",
        "*Acc test - 89.98%*\n",
        "\n",
        "*Acc train - 94.84%*\n",
        "\n",
        "*Acc Train - Acc test = 4.86%*"
      ],
      "metadata": {
        "id": "rzNpjeJgWj69"
      }
    }
  ]
}